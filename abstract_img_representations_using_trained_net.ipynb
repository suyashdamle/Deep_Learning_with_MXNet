{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: Logistic Regression using Transfer Learning\n",
    "\n",
    "- Only 50 iterations of the Logistic Regression functions is run with the default parameters left unchanged. Tweaking these parameters might lead to better accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suyash/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "display_step=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/suyash/New Volume/IIT KGP/DeepLearning\n"
     ]
    }
   ],
   "source": [
    "class DataLoader(object):\n",
    "    DIR=None\n",
    "    import os\n",
    "    print(os.getcwd())\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.DIR = './'\n",
    "    \n",
    "    # Returns images and labels corresponding for training and testing. Default mode is train. \n",
    "    # For retrieving test data pass mode as 'test' in function call.\n",
    "    def load_data(self, mode = 'train'):\n",
    "        label_filename = mode + '_labels'\n",
    "        image_filename = mode + '_images'\n",
    "        label_zip = self.DIR + label_filename + '.zip'\n",
    "        image_zip = self.DIR + image_filename + '.zip'\n",
    "        with ZipFile(label_zip, 'r') as lblzip:\n",
    "            labels = np.frombuffer(lblzip.read(label_filename), dtype=np.uint8, offset=8)\n",
    "        with ZipFile(image_zip, 'r') as imgzip:\n",
    "            images = np.frombuffer(imgzip.read(image_filename), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
    "        return images, labels\n",
    "    \n",
    "    \n",
    "    def create_batches(self,train_size):\n",
    "        '''\n",
    "        Handles the train-validation split \n",
    "        Params:\n",
    "            train_size: ratio of train_size : float\n",
    "        Returns:\n",
    "            images, labels, validation images, validation labels in that order\n",
    "        '''\n",
    "        img,labels=self.load_data()\n",
    "        n=labels.shape[0]\n",
    "        #split into train and validation data\n",
    "        validation_img=img[int(train_size*n):]\n",
    "        img=img[:int(train_size*n)]\n",
    "        validation_labels=labels[int(train_size*n):]\n",
    "        labels=labels[:int(train_size*n)]\n",
    "        return img, labels, validation_img, validation_labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=DataLoader()\n",
    "data,label=data_loader.load_data(mode='train')\n",
    "batch_size=data.shape[0]\n",
    "train_iter = mx.io.NDArrayIter(data, label, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Network 2 completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = mx.symbol.Variable('data')\n",
    "fc1_new  = mx.symbol.FullyConnected(data = data_new, num_hidden=1024,name='fc1')\n",
    "act1_new = mx.symbol.Activation(data = fc1_new, act_type=\"relu\",name='act1')\n",
    "fc2_new  = mx.symbol.FullyConnected(data = act1_new, num_hidden = 512,name='fc2')\n",
    "act2_new = mx.symbol.Activation(data = fc2_new, act_type=\"relu\",name='act2')\n",
    "fc3_new  = mx.symbol.FullyConnected(data = act2_new, num_hidden = 256,name='fc3')\n",
    "act3_new = mx.symbol.Activation(data = fc3_new, act_type=\"relu\",name='act3')\n",
    "\n",
    "#output layer\n",
    "fc4_new  = mx.symbol.FullyConnected(data = act3_new, num_hidden=10,name='fc4')\n",
    "mlp_new = mx.symbol.SoftmaxOutput(data = fc4_new,name='softmax')\n",
    "mod_new = mx.mod.Module(symbol=mlp_new,\n",
    "                    context=mx.cpu(),\n",
    "                    data_names=['data'],\n",
    "                    label_names=['softmax_label'])\n",
    "mod_new.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "mod_new.load_params('network2_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_new=mlp_new.get_internals()['fc1_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_trans = mx.mod.Module(symbol=sym_new, context=mx.cpu(),data_names=['data'],label_names=None)\n",
    "mod_trans.bind(for_training=False, data_shapes=train_iter.provide_data)\n",
    "arg_params, aux_params = mod_new.get_params()\n",
    "mod_trans.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1024)\n"
     ]
    }
   ],
   "source": [
    "train_iter.reset()\n",
    "for batch in train_iter:\n",
    "    mod_trans.forward(batch)\n",
    "    out_trans=mod_trans.get_outputs()[0].asnumpy()\n",
    "print(out_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# obtaining test image transforms:\n",
    "test_img,test_labels=data_loader.load_data(mode='test')\n",
    "test_iter = mx.io.NDArrayIter(test_img,batch_size=test_img.shape[0])\n",
    "test_iter.reset()\n",
    "for batch in test_iter:\n",
    "    mod_trans.forward(batch)\n",
    "    out_trans_test=mod_trans.get_outputs()[0].asnumpy()\n",
    "print(out_trans_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with data transformed to different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "clf=LogisticRegression(max_iter=50,solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on classification task using features from neural net:  0.1251\n"
     ]
    }
   ],
   "source": [
    "clf.fit(out_trans,label)\n",
    "y_predicted=clf.predict(out_trans_test)\n",
    "accuracy=accuracy_score(test_labels,y_predicted)\n",
    "print(\"Accuracy on classification task using features from neural net: \", accuracy)\n",
    "pickle.dump(clf,open('layer1','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 512)\n"
     ]
    }
   ],
   "source": [
    "sym_new=mlp_new.get_internals()['fc2_output']\n",
    "mod_trans = mx.mod.Module(symbol=sym_new, context=mx.cpu(),data_names=['data'],label_names=None)\n",
    "mod_trans.bind(for_training=False, data_shapes=train_iter.provide_data)\n",
    "arg_params, aux_params = mod_new.get_params()\n",
    "mod_trans.set_params(arg_params, aux_params)\n",
    "train_iter.reset()\n",
    "for batch in train_iter:\n",
    "    mod_trans.forward(batch)\n",
    "    out_trans=mod_trans.get_outputs()[0].asnumpy()\n",
    "print (out_trans.shape)\n",
    "test_iter.reset()\n",
    "for batch in test_iter:\n",
    "    mod_trans.forward(batch)\n",
    "    out_trans_test=mod_trans.get_outputs()[0].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on classification task using features from second layer:  0.0983\n"
     ]
    }
   ],
   "source": [
    "clf.fit(out_trans,label)\n",
    "y_predicted=clf.predict(out_trans_test)\n",
    "accuracy=accuracy_score(test_labels,y_predicted)\n",
    "print(\"Accuracy on classification task using features from second layer: \", accuracy)\n",
    "pickle.dump(clf,open('layer2','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 256)\n",
      "Accuracy on classification task using features from third layer:  0.0847\n"
     ]
    }
   ],
   "source": [
    "sym_new=mlp_new.get_internals()['fc3_output']\n",
    "mod_trans = mx.mod.Module(symbol=sym_new, context=mx.cpu(),data_names=['data'],label_names=None)\n",
    "mod_trans.bind(for_training=False, data_shapes=train_iter.provide_data)\n",
    "arg_params, aux_params = mod_new.get_params()\n",
    "mod_trans.set_params(arg_params, aux_params)\n",
    "train_iter.reset()\n",
    "for batch in train_iter:\n",
    "    mod_trans.forward(batch)\n",
    "    out_trans=mod_trans.get_outputs()[0].asnumpy()\n",
    "print (out_trans.shape)\n",
    "test_iter.reset()\n",
    "for batch in test_iter:\n",
    "    mod_trans.forward(batch)\n",
    "    out_trans_test=mod_trans.get_outputs()[0].asnumpy()\n",
    "clf.fit(out_trans,label)\n",
    "y_predicted=clf.predict(out_trans_test)\n",
    "accuracy=accuracy_score(test_labels,y_predicted)\n",
    "print(\"Accuracy on classification task using features from third layer: \", accuracy)\n",
    "pickle.dump(clf,open('laye3','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
